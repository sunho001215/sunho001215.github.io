---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

> **Deep Learning Hardware Design Competition 2022**  
> *AI Accelerator Design Competition for Undergraduate Students*  
> *Feb 2022 - Jul 2022*
> <details>
> <summary>Click to toggle details</summary>
> 
> <p><b>Project Description</b> <br>
> This competition is organized by Polaris, South Korea's next-generation Semiconductor Convergence University, and is targeted at college students nationwide. The goal of the competition is to run the Yolov3 model on an FPGA board, and the team that designs the fastest and most energy-efficient hardware will be declared the winner. </p> 
> 
> <p><b>Details</b> <br>
> <img src='/images/AIX-structure.png' width="670" height="400"/> <br>
> Our team designed a high-performance and power-efficient FPGA implementation for CNN inference, which includes an adder-tree-based computational unit tailored for the Tiny-YOLO v3 model and a datapath that minimizes buffer usage while maximizing computational parallelism, effectively optimizing performance within the constraints of limited on-chip memory. </p> 
> 
> <p><b>Remarks</b> <br>
> Our team presented in a special session at <a href="https://aicas2022.org/?page_id=188">IEEE AICAS 2022</a> and secured 2nd place out of 111 teams, winning a $2,000 prize. </p> 
> 
> <p><b>Photo</b> <br>
> <img src='/images/AIX-result.png'/> <br>
> </p> 
> 
> </details>


> **HMG Autonomous Driving Challenge 2021**  
> *Hyundai Motorâ€™s Autonomous Driving Competition for Undergraduate/Graduate Students*  
> *Aug 2020 - Feb 2021*
> <details>
> <summary>Click to toggle details</summary>
> 
> <p><b>Project Description</b> <br>
> <img src='/images/CarMaker.webp'/> <br>
> This competition is organized by Hyundai Motor and is open to both undergraduate and graduate students in Korea. The preliminary round takes place in the CarMaker simulation environment, where participants undertake various tasks such as dynamic obstacle avoidance, static obstacle avoidance, traffic light handling, and lane-keeping. The final round retains similar missions but is conducted using modified real vehicles. </p> 
> 
> <p><b>Details</b> <br>
> I developed software to execute various missions in the CarMaker simulation, contributing to the development of object detection through a modified version of YOLO v3, object tracking using Kalman Filter with lidar and camera, and implementing an Optimal Frenet Planning algorithm for path planning (<a href="https://vdcl.snu.ac.kr/members/professor">GitHub</a>). </p> 
> 
> <p><b>Remarks</b> <br>
> Our team participated in this competition up to the preliminary round after passing the document screening. The entire process of the project was carried out under the guidance of Professor <a href="https://vdcl.snu.ac.kr/members/professor">Kyongsu Yi</a> at Seoul National University. </p> 
> 
> </details>

> **K-Startup Maker Project 2020**  
> *Maker Project hosted by the Korean Government (K-Startup)*  
> *Jul 2020 - Dec 2020*  
> <details>
> <summary>Click to toggle details</summary>
> 
> <p><b>Project Description</b> <br>
> This project is one of the maker projects, which involve creative activities using digital devices and various tools to bring one's ideas to life, supported by the Ministry of SMEs and Startups of the South Korean government. It's an inclusive project that allows participation from high school students to university students and even working professionals. </p> 
> 
> <p><b>Details</b> <br>
> The goal of this project was to control a robot without attaching any sensors to it, aside from actuators. We set this objective because we believe that the multitude of sensors typically attached to robots increases production costs, making it difficult for them to be widely adopted in our society. To control the robot, we installed multiple external cameras and performed driving area detection using U-Net and robot position detection using DOPE. To generate training data, we set up a ROS Gazebo simulation environment, which provided the necessary data for learning, and subsequently applied it to a real-world setting. I served as the overall team leader for the project, where we used TurtleBot as our robot platform. (<a href="https://github.com/snuzero2020/zero_maker">GitHub</a>) </p> 
> 
> <p><b>Remarks</b> <br>
> This project was carried out with a grant of 5,000 dollars. </p> 
> 
> <p><b>Photo</b> <br>
> TurtleBot <br>
> <img src='/images/zero-1.jpg' width="600" height="450"/> <br>
> Driving Area Detection (U-Net) <br>
> <img src='/images/zero-2.bmp' width="600" height="450"/>
> <img src='/images/zero-3.bmp' width="600" height="450"/> <br>
> Robot Position Detection (DOPE) <br>
> <img src='/images/zero-4.bmp' width="600" height="450"/>
> <img src='/images/zero-5.bmp' width="600" height="450"/> <br>
> </p> 
> </details>

> **X-Corps Project 2020**  
> *Undergraduate Project hosted by Seoul National University*  
> *Jul 2020 - Dec 2020*  
> <details>
> <summary>Click to toggle details</summary>
> 
> <p><b>Project Description</b> <br>
> This project is supported by the Practical Problem Research Group at Seoul National University. The aim of this project is to cultivate talents capable of solving real-world problems by supporting interdisciplinary research tasks primarily led by undergraduate students. </p> 
> 
> <p><b>Details</b> <br>
> The theme and content of this project are identical to those of the K-Startup Maker Project 2020. </p> 
> 
> <p><b>Remarks</b> <br>
> This project was carried out with a grant of 5,000 dollars, and as a result of the competition, we received an excellence prize along with a prize money of 1,000 dollars. The entire process of the project was carried out under the guidance of Professor <a href="https://rllab.snu.ac.kr/people/songhwai-oh">Songhwai Oh</a> at Seoul National University. </p> 
> 
> </details>

> **International Student Car Competition 2020**  
> *Autonomous Driving Competition for International Students*  
> *Mar 2020 - Aug 2020*  
> <details>
> <summary>Click to toggle details</summary>
> 
> <p><b>Project Description</b> <br>
> This competition is an undergraduate contest organized by the Ministry of Land, Infrastructure, and Transport of South Korea. It involves various tasks such as static obstacle avoidance, dynamic obstacle avoidance, traffic light recognition, parking, and curve driving. Awards are given to the teams that complete all missions in the shortest amount of time. This competition encompasses everything from building a platform capable of autonomous driving to developing the autonomous driving software itself. </p> 
> 
> <p><b>Details</b> <br>
> <iframe width="560" height="315" src="https://www.youtube.com/embed/EEYO5-M3jzM?si=ExjMZN9KNvOAHDF4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br>
> I served as the Deputy Team Leader for the entire project and concurrently held the position of Team Leader for the Vision Team. The project was conducted at the Future Mobility Technology Center (FMTC) at Seoul National University. Our team implemented an autonomous driving platform using two cameras, one LiDAR, one GPS, and one IMU. We developed a comprehensive autonomous driving algorithm that includes HD map creation, localization, path-planning, object detection and vision algorithms. I developed autonomous driving software, focusing particularly on real-time parking slot detection using a modified version of YOLO v3, traffic light detection with YOLO v3, and lane detection utilizing the LaneNet algorithm. (<a href="https://github.com/snuzero2020/zero">GitHub</a>)</p> 
> 
> <p><b>Remarks</b> <br>
> The entire process of this competition was conducted under the guidance and assistance of <a href="https://vdcl.snu.ac.kr/members/professor">Kyongsu Yi</a> and Dr. Lee Jae-wan. </p> 
> 
<!-- > <p><b>Photo</b> <br>
> <img src='/images/zero-1.jpg'/> <br>
> <img src='/images/zero-2.jpg'/> <br>
> <img src='/images/zero-3.jpg'/> <br>
> </p> -->
>
> </details>

> **Autonomous Delivery Project**  
> *Autonomous Delivery Project conducted by [Autonomous Robot Intelligence Lab.](https://arisnu.squarespace.com/)*  
> *Jan 2020 - Feb 2020*
> <details>
> <summary>Click to toggle details</summary>
> 
> <p><b>Project Description</b> <br>
> This project was conducted at ARI lab, and the goal of the project is to develop a delivery robot capable of delivering food without human intervention. </p> 
> 
> <p><b>Details</b> <br>
> <iframe width="560" height="315" src="https://www.youtube.com/embed/hNRs1_4xCZg?si=IwGqDo_XmYC7_GKi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br>
> I participated in the initial phase of the project. (<a href="https://www.youtube.com/watch?v=hNRs1_4xCZg">YouTube</a>) </p> 
> 
> <p><b>Remarks</b> <br>
> The entire process of the project was carried out under the guidance of Professor <a href="https://arisnu.squarespace.com/director">Sungwoo Kim</a> at Seoul National University. </p> 
> 
> </details>

> **DYROS Robotics Boot Camp**  
> *DYROS Bootcamp for ROS (Robot Operating System) and Linux*  
> *Jan 2019*  
> <details>
> <summary>Click to toggle details</summary>
> 
> <p><b>Description</b> <br>
> DYROS Boot Camp is an educational program conducted by <a href="http://dyros.snu.ac.kr/features/about-us/">DYROS lab</a>, offering lectures on ROS, Linux, and robot simulators. </p> 
> 
> </details>
